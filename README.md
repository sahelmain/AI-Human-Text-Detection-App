# AI vs Human Text Detection System

ü§ñüìù **A machine learning web application that distinguishes between human-written and AI-generated text using multiple classification algorithms.**

## üìã Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Model Performance](#model-performance)
- [Project Structure](#project-structure)
- [Technical Details](#technical-details)
- [Contributing](#contributing)

## üéØ Overview

This project implements a comprehensive text classification system to detect whether text content was written by humans or generated by AI. The system uses three different machine learning algorithms:
- **Support Vector Machine (SVM)** - 96.38% accuracy
- **Decision Tree** - 84.99% accuracy  
- **AdaBoost** - 85.50% accuracy

## üöÄ Features

### Core Functionality
- **Single Text Analysis**: Analyze individual text samples with detailed explanations
- **Batch Processing**: Process multiple texts simultaneously and export results
- **Model Comparison**: Compare predictions across all three models
- **Confidence Scoring**: Get reliability scores for each prediction

### User Interface
- **Interactive Web App**: Built with Streamlit for easy use
- **Real-time Predictions**: Instant analysis with visual feedback
- **File Upload Support**: Process text files directly
- **Export Results**: Download batch results as CSV

### Technical Features
- **Advanced Preprocessing**: NLTK-based text cleaning and normalization
- **TF-IDF Vectorization**: Optimized feature extraction
- **Multiple ML Models**: Ensemble of different algorithms
- **Statistical Analysis**: Confidence intervals and significance testing

## üõ† Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Quick Start

1. **Clone the repository**
   ```bash
   git clone <your-repository-url>
   cd ai_human_detection_project
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Download NLTK data** (automatic on first run)
   ```python
   import nltk
   nltk.download('punkt')
   nltk.download('stopwords')
   nltk.download('wordnet')
   ```

4. **Run the application**
   ```bash
   streamlit run app.py
   ```

5. **Open in browser**
   The app will automatically open at `http://localhost:8501`

### Dependencies

```txt
pandas>=2.0.0
numpy>=1.26.0
scikit-learn>=1.4.0
matplotlib>=3.7.1
seaborn>=0.12.2
plotly>=5.15.0
joblib>=1.3.2
streamlit
nltk>=3.8
```

## üì± Usage

### Single Text Analysis
1. Navigate to "Single Text Analysis" page
2. Enter or paste your text
3. Select a model (SVM recommended for highest accuracy)
4. Click "Analyze Text"
5. View prediction, confidence score, and detailed metrics

### Batch Processing
1. Go to "Batch Processing" page
2. Choose input method:
   - Upload CSV file with 'text' column
   - Enter multiple texts (one per line)
3. Select model for processing
4. Click "Process Batch"
5. Download results as CSV

### Model Comparison
1. Visit "Model Comparison" page
2. Enter text to analyze
3. Click "Compare Models"
4. View predictions from all three models side-by-side

## üìä Model Performance

### Accuracy Metrics
| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| SVM | 96.38% | 96.38% | 96.38% | 96.38% |
| Decision Tree | 84.99% | 85.02% | 84.99% | 84.98% |
| AdaBoost | 85.50% | 85.45% | 85.50% | 85.47% |

### Cross-Validation Results
- **SVM**: 97.28% ¬± 1.09% (5-fold CV)
- **Decision Tree**: 85.32% ¬± 2.15% (5-fold CV)
- **AdaBoost**: 85.68% ¬± 1.98% (5-fold CV)

### Statistical Significance
- SVM significantly outperforms other models (p < 0.001)
- Large effect size (Cohen's d = 2.476)
- 95% confidence intervals do not overlap

## üìÅ Project Structure

```
ai_human_detection_project/
‚îú‚îÄ‚îÄ app.py                          # Main Streamlit application
‚îú‚îÄ‚îÄ requirements.txt                # Project dependencies
‚îú‚îÄ‚îÄ README.md                       # Project documentation
‚îú‚îÄ‚îÄ models/                         # Trained ML models
‚îÇ   ‚îú‚îÄ‚îÄ svm_model.pkl              # Support Vector Machine
‚îÇ   ‚îú‚îÄ‚îÄ decision_tree_model.pkl    # Decision Tree classifier
‚îÇ   ‚îú‚îÄ‚îÄ adaboost_model.pkl         # AdaBoost ensemble
‚îÇ   ‚îî‚îÄ‚îÄ tfidf_vectorizer.pkl       # TF-IDF vectorizer
‚îú‚îÄ‚îÄ data/                           # Training and test data
‚îÇ   ‚îú‚îÄ‚îÄ training_data/             # Training dataset
‚îÇ   ‚îî‚îÄ‚îÄ test_data/                 # Test documents
‚îî‚îÄ‚îÄ notebooks/                      # Development notebooks
    ‚îî‚îÄ‚îÄ AI_Human_Detection.ipynb   # Model development
```

## üîß Technical Details

### Text Preprocessing Pipeline
1. **Lowercasing**: Convert all text to lowercase
2. **Special Character Removal**: Remove non-alphabetic characters
3. **Whitespace Normalization**: Clean extra spaces
4. **TF-IDF Vectorization**: Convert to numerical features

### Model Specifications

#### SVM (Best Performing)
- **Kernel**: Sigmoid
- **Regularization**: Optimized via Grid Search
- **Features**: TF-IDF vectors (max_features=5000)
- **Cross-validation**: 5-fold stratified

#### Decision Tree
- **Criterion**: Gini impurity
- **Max Depth**: 10 (optimized)
- **Min Samples Split**: 2
- **Pruning**: Applied for generalization

#### AdaBoost
- **Base Estimator**: Decision Trees (max_depth=1)
- **N Estimators**: 100
- **Learning Rate**: 1.0
- **Algorithm**: SAMME.R

### Feature Engineering
- **TF-IDF**: Term Frequency-Inverse Document Frequency
- **Vocabulary Size**: 5,000 most important features
- **N-grams**: Unigrams and bigrams
- **Min/Max DF**: Filtered rare and common terms

## üéØ Best Practices

### Model Selection Guidelines
- **Use SVM** for highest accuracy (96.38%)
- **Use Decision Tree** for interpretability
- **Use AdaBoost** for ensemble robustness

### Text Input Recommendations
- **Minimum length**: 50-100 words for reliable results
- **Content type**: Works best with essay-style text
- **Language**: Optimized for English text
- **Format**: Plain text preferred

### Confidence Score Interpretation
- **80-100%**: High confidence - very reliable
- **60-79%**: Medium confidence - generally reliable
- **<60%**: Low confidence - consider manual review

## üêõ Troubleshooting

### Common Issues

**Error: "Models not found"**
- Ensure all `.pkl` files are in the `models/` directory
- Check file permissions

**Low prediction confidence**
- Text might be too short
- Content may be outside training domain
- Try different model

**NLTK download errors**
- Run: `python -c "import nltk; nltk.download('all')"`
- Check internet connection

**Streamlit port issues**
- Use: `streamlit run app.py --server.port 8502`
- Check for port conflicts

## ü§ù Contributing

### Development Setup
1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Make changes and test thoroughly
4. Submit pull request with detailed description

### Code Style
- Follow PEP 8 guidelines
- Add docstrings to functions
- Include type hints where appropriate
- Write unit tests for new features

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üë®‚Äçüíª Author

**Sahel Azzam**
- Course: Intro To Large Language Models and Intro to AI Agents
- Assignment: Advanced Text Classification Project

## üôè Acknowledgments

- Scikit-learn team for machine learning tools
- Streamlit team for the web framework
- NLTK team for natural language processing
- Course instructors for guidance and requirements

---

## üìû Support

If you encounter any issues or have questions:

1. Check this README for common solutions
2. Review the troubleshooting section
3. Ensure all dependencies are properly installed
4. Verify model files are present and accessible

For technical issues, please check:
- Python version compatibility (3.8+)
- All required packages installed
- Sufficient disk space for model files
- Network connectivity for NLTK downloads

---

**üöÄ Ready to detect AI-generated text? Run `streamlit run app.py` and start analyzing!** 